{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96ecd627",
   "metadata": {},
   "source": [
    "# Review Analyzer\n",
    "### By Revanth Krishna Bachu\n",
    "\n",
    "This code analyzes reviews to predict the rating the reviewer might have given, an analysis of the review, and a list of tags for the review. It will also compile the tags into a file and sort them from most to least occurring within all of the reviews.\n",
    "\n",
    "\n",
    "**Things to keep in mind:**\n",
    "\n",
    "The ChatGpt API can only take 3 requests per minute for non subscription members\n",
    "\n",
    "This code uses the GPT-3.5 Turbo model. Pricing for all the models can be found at https://openai.com/pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0545899c",
   "metadata": {},
   "source": [
    "First, run the following 3 cells. Then start running the cells for either the Single Review Analyzer or the Multiple Review Analyzer depending on which you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7bfc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ef2146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d22aef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = input(\"Enter your OpenAPI Key here:  \")\n",
    "openai.api_key = api_key\n",
    "time_between_messages = 60 / 3 #Non Subscription members have a limit of 3 requests per minute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bab7ca",
   "metadata": {},
   "source": [
    "# Single Review Analyzer\n",
    "\n",
    "You will be prompted for the review, and the predicted rating, analysis, and tags will be printed out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05f9f72-5f40-48d8-96c7-22e62db30b72",
   "metadata": {},
   "source": [
    "If you have a gpt 4 key, you can use this code to add an image to give the model more context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94542e9-004b-4b8e-8145-b956a5e18c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "user_input=input(\"Enter your review here:  \")\n",
    "\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = input(\"Enter your image path: \")\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "  \"model\": \"gpt-4o-mini\",\n",
    "  \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": \"You may only answer with a single number.\"},\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What rating between 0 and 5 inclusive do you think this reviewer would give based on their review and image: \"+user_input+\"/n Give only the number.\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 300\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c9debd-540b-49bc-a558-e978a39c579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "  \"model\": \"gpt-4o-mini\",\n",
    "  \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": \"You may only answer with a list in the format of: -item1\\n-item2\"},\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"Summarize the main points of this review into a list of generic tags: \"+user_input\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 300\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "print(response.json())\n",
    "\n",
    "payload = {\n",
    "  \"model\": \"gpt-4o-mini\",\n",
    "  \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": \"ou are a helpful assistant\"},\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"Give me a summary of feedback from this review: \"+user_input\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 300\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838390d6-72ff-4958-b695-ca91e2fd5977",
   "metadata": {},
   "source": [
    "Use this code instead if you do not have access to gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341a7c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input=input(\"Enter your review here:  \")\n",
    "\n",
    "r = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You may only answer with a single number.\"}, \n",
    "        {\"role\": \"user\", \"content\": \"What rating between 0 and 5 inclusive do you think this reviewer would give based on their review: \"+user_input+\"/n Give only the number.\"}\n",
    "    ]\n",
    ")\n",
    "    \n",
    "t = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You may only answer with a list in the format of: -item1\\n-item2\"}, \n",
    "        {\"role\": \"user\", \"content\": \"Summarize the main points of this review into a list of generic tags: \"+user_input}\n",
    "    ]\n",
    ")\n",
    "    \n",
    "f = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"}, \n",
    "        {\"role\": \"user\", \"content\": \"Give me a summary of feedback from this review: \"+user_input}\n",
    "    ]\n",
    ")\n",
    "    \n",
    "    #Calling the models for chatgpt's answer; each call must be staggered to work within the number of calls per minute\n",
    "    \n",
    "predicted_rating = r.choices[0].message.content\n",
    "time.sleep(time_between_messages)\n",
    "predicted_tags= t.choices[0].message.content\n",
    "time.sleep(time_between_messages)\n",
    "predicted_feedback= f.choices[0].message.content\n",
    "\n",
    "print(\"\\nPredicted Rating: \", predicted_rating)\n",
    "print(\"\\nAnalysis: \", predicted_feedback)\n",
    "print(\"\\nTags: \", predicted_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76985b7a",
   "metadata": {},
   "source": [
    "# Multiple Reviews Analyzer\n",
    "\n",
    "You will be prompted to enter in the file paths for the file with all your reviews (which must be spaced so that there is a completely blank line between each review), and the two files that are to be written to, one file that contains the predicted rating, analysis, and tags for each review, and the other file contains the tags from all the reviews ordered by frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c51f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_reviews = input(\"Enter the path of the file with the reviews: \")                     #File with all the reviews, the reviews must be spaced out with a full blank line\n",
    "file_path_analysis = input(\"Enter the path of the file that will hold the analysis: \")         #File where the full analysis will go\n",
    "file_path_tags= input(\"Enter the path of the file that will hold the sorted tags:  \")          #File where the sorted tags will go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17577ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the file of Reviews to read, then split them up into an array of strings\n",
    "#Reviews in the reviews file should be seperated by a whole blank line\n",
    "try:\n",
    "    with open(file_path_reviews, \"r\") as file:\n",
    "        content = file.read()\n",
    "    reviews = content.split(\"\\n\\n\")\n",
    "    reviews = [review.strip() for review in reviews]\n",
    "except:\n",
    "    print(\"Error occured with file path: \", file_path_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e07da",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_predictions=[]\n",
    "analysis=[]\n",
    "tagging=[]\n",
    "for review in reviews:\n",
    "    \n",
    "    #Initialization of the models with the review\n",
    "    \n",
    "    r = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You may only answer with a single number.\"}, \n",
    "        {\"role\": \"user\", \"content\": \"What rating between 0 and 5 inclusive do you think this reviewer would give based on their review: \"+review+\"/n Give only the number.\"}\n",
    "      ]\n",
    "    )\n",
    "    \n",
    "    t = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You may only answer with a list in the format of: -item1\\n-item2\"}, \n",
    "        {\"role\": \"user\", \"content\": \"Summarize the main points of this review into a list of generic tags: \"+review}\n",
    "      ]\n",
    "    )\n",
    "    \n",
    "    f = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"}, \n",
    "        {\"role\": \"user\", \"content\": \"Give me a summary of feedback from this review: \"+review}\n",
    "      ]\n",
    "    )\n",
    "    \n",
    "    #Calling the models for chatgpt's answer; each call must be staggered to work within the number of calls per minute\n",
    "    \n",
    "    rating = r.choices[0].message.content\n",
    "    time.sleep(time_between_messages)\n",
    "    tags= t.choices[0].message.content\n",
    "    time.sleep(time_between_messages)\n",
    "    feedback= f.choices[0].message.content\n",
    "    time.sleep(time_between_messages)\n",
    "    \n",
    "    #add the answers to an array of stings\n",
    "    \n",
    "    rating_predictions.append(rating)\n",
    "    analysis.append(feedback)\n",
    "    tagging.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c819fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opens a text file to write the overall analysis\n",
    "try:\n",
    "    with open(file_path_analysis, \"w\") as file:\n",
    "        for r, c, a, t, in zip(reviews, rating_predictions, analysis, tagging):\n",
    "            file.write(\"Review: \"+r+\"\\n\\n\")\n",
    "            file.write(\"Predicted Rating:\\n \"+c+\"\\n\\n\")\n",
    "            file.write(\"Analysis: \"+a+\"\\n\\n\")\n",
    "            file.write(\"Predicted Tags: \\n\"+t+\"\\n\\n\")\n",
    "except:\n",
    "    print(\"Error occured with file path: \", file_path_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9542143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To order the tags and find their occurence, a dictionary is made and assigned all the induvidual tags from each review\n",
    "\n",
    "d={}\n",
    "for tags in tagging:\n",
    "    li = tags.strip().split('\\n')\n",
    "    for tag in li:\n",
    "        key = tag[1:]  #chatgpt uses hyphens at the start of every item in the list so we start from the second character\n",
    "        if key in d:\n",
    "            d[key] =d[key]+1\n",
    "        else:\n",
    "            d[key] = 1\n",
    "\n",
    "#the \"sorted\" fucntion will sort the dictionary into descending order based on the amount of times the tag occured\n",
    "\n",
    "sd=dict(sorted(d.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "#the sorted tags are then written into another file, along with the number of times they occured\n",
    "try:\n",
    "    with open(file_path_tags, \"w\") as file:\n",
    "        for key, value in sd.items():\n",
    "            file.write(key+\": \"+str(value)+\"\\n\\n\")\n",
    "except:\n",
    "    print(\"Error occured with file path: \", file_path_tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
